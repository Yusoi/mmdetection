{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7abd8276-9a15-493d-9702-193567232dc8",
   "metadata": {
    "id": "7abd8276-9a15-493d-9702-193567232dc8"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "N_CHANNELS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a6e7996-329c-4b1e-9096-66673a04f309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "import torch\n",
    "from network_definitions.u_net import UNet\n",
    "from network_definitions.fcn import FCN32s as FCN\n",
    "from network_definitions.simple_network import SimpleNet\n",
    "from network_definitions.pyramid_network import PyramidNet\n",
    "from torchvision.models.segmentation import fcn_resnet101 as FCN_Res101"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125d6836-3303-4a58-909e-e8ebbf7c36b8",
   "metadata": {
    "id": "125d6836-3303-4a58-909e-e8ebbf7c36b8"
   },
   "source": [
    "# Dataset Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6d8e490-235c-4b8b-86e4-5032f56012c5",
   "metadata": {
    "id": "a6d8e490-235c-4b8b-86e4-5032f56012c5",
    "outputId": "5f5e2dec-91aa-46b3-d42b-e40967cada91"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import pickle\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "class EnsembleDataset(Dataset):\n",
    "    \"\"\"Ensemble dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, results_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            results_file (string): File with all the results.\n",
    "        \"\"\"\n",
    "        with open(results_file, 'rb') as f:\n",
    "            #compressed_file = bz2.BZ2File(f, 'r')\n",
    "            self.results = pickle.load(f)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.results)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        data = self.results[idx]\n",
    "        sample = {'name': data[0], 'valid': data[1], 'im_seg': data[2], 'im_res': data[3]}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "KitU2dCDKiud",
   "metadata": {
    "id": "KitU2dCDKiud"
   },
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "class Resize(object):\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self,sample):\n",
    "        name,valid,im_seg,im_res = sample[\"name\"],sample[\"valid\"],sample[\"im_seg\"],sample[\"im_res\"]\n",
    "        \n",
    "        return {\"name\": name, \"valid\": valid, \"im_seg\": resize(im_seg,(self.size,self.size,N_CHANNELS),preserve_range=True), \"im_res\": resize(im_res,(self.size,self.size,1),preserve_range=True)}\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        name,valid,im_seg,im_res = sample[\"name\"],sample[\"valid\"],sample[\"im_seg\"],sample[\"im_res\"]\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C x H x W\n",
    "        im_seg = im_seg.transpose((2, 0, 1))\n",
    "        im_res = im_res.transpose((2, 0, 1))\n",
    "        return {\"name\": name, \n",
    "                \"valid\": valid,\n",
    "                \"im_seg\": torch.from_numpy(im_seg),\n",
    "                \"im_res\": torch.from_numpy(im_res)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8933d255-781d-47e7-a4df-af65c74a37a1",
   "metadata": {
    "id": "8933d255-781d-47e7-a4df-af65c74a37a1",
    "outputId": "b0e15282-db09-460f-e923-ed51732716d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"trainset = EnsembleDataset(image_dir='data/coco/test2017',\\n                           results_file='',\\n                           transform=transforms.Compose([Rescale(256),\\n                                                         RandomCrop(224),\\n                                                         ToTensor()]))\\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\\n                                          shuffle=True, num_workers=2)\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset = EnsembleDataset(results_file='work_dirs/dataset_generation/dataset_no_img.pkl', \n",
    "                           transform=transforms.Compose([Resize(572),\n",
    "                                                         ToTensor()]))\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=6)\n",
    "\n",
    "\"\"\"trainset = EnsembleDataset(image_dir='data/coco/test2017',\n",
    "                           results_file='',\n",
    "                           transform=transforms.Compose([Rescale(256),\n",
    "                                                         RandomCrop(224),\n",
    "                                                         ToTensor()]))\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79005d77-36ac-4f74-8b20-74f6c6ac50c5",
   "metadata": {
    "id": "79005d77-36ac-4f74-8b20-74f6c6ac50c5"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04b1957d-e096-404f-ba42-6e3f3cf717a5",
   "metadata": {
    "id": "04b1957d-e096-404f-ba42-6e3f3cf717a5"
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#PATH = \"work_dirs/simplenet_1/\"\n",
    "\n",
    "\n",
    "def train(net, trainloader, criterion, optimizer, save_path, tensorboard_path, checkpoint=None):\n",
    "    \n",
    "    EPOCH = 0\n",
    "    \n",
    "    writer = SummaryWriter(log_dir=tensorboard_path)\n",
    "    \n",
    "    if checkpoint != None:\n",
    "        checkpoint = torch.load(checkpoint)\n",
    "        net.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        EPOCH = checkpoint['epoch']\n",
    "        loss = checkpoint['loss']\n",
    "        net.train()\n",
    "    \n",
    "    for epoch in range(EPOCH,25):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            im_seg = data[\"im_seg\"].to(device, dtype=torch.float)\n",
    "            im_res = data[\"im_res\"].to(device, dtype=torch.float)\n",
    "            valid = data[\"valid\"].to(device, dtype=torch.long)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            out_segm,out_class = net(im_seg.float())\n",
    "            loss_segm = criterion[0](out_segm, im_res.float())\n",
    "            #loss_class = criterion[1](torch.round(out_class.cpu().detach()).type(torch.LongTensor), valid.cpu().detach())\n",
    "            loss_class = 0\n",
    "            loss = loss_segm+loss_class\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            #running_loss_segm += loss_segm.item()\n",
    "            #running_loss_segm += loss_class.item()\n",
    "            running_loss += loss.item()\n",
    "            if i % 50 == 49:    # print every 2000 mini-batches\n",
    "                \"\"\"print('[%d, %5d] segm loss: %.6f  class loss: %.6f  loss: %.6f' %\n",
    "                      (epoch + 1, i + 1, running_loss_segm / 50, running_loss_class / 50, running_loss / 50))\"\"\"\n",
    "                print('[%d, %5d] loss: %.6f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 50))\n",
    "                running_loss = 0.0\n",
    "                inp = im_seg.cpu().detach()\n",
    "                output = out_segm.cpu().detach()\n",
    "                output_rounded = torch.round(output)\n",
    "                gt_output = im_res.cpu().detach()\n",
    "                out_class = out_class.cpu().detach()\n",
    "                \n",
    "                inp = inp.numpy()[0].transpose((1,2,0))\n",
    "                #.squeeze(axis=0)\n",
    "                output = output.numpy()[0].transpose((1,2,0)).squeeze(axis=2)\n",
    "                output_rounded = output_rounded.numpy()[0].transpose((1,2,0)).squeeze(axis=2)\n",
    "                gt_output = gt_output.numpy()[0].transpose((1,2,0)).squeeze(axis=2)\n",
    "                \n",
    "                fig, ax = plt.subplots(nrows=1, ncols=8, figsize=(15,15))\n",
    "                ax=ax.flat\n",
    "                \n",
    "                for i in range(0,5):\n",
    "                    #ax.append(fig.add_subplot(2, 4, i+1))\n",
    "                    ax[i].set_title(\"Input \"+str(i+1))  # set title\n",
    "                    ax[i].imshow(inp[:,:,i],cmap='gray',vmin=0,vmax=1)\n",
    "                    \n",
    "                \n",
    "                    \n",
    "                #ax.append(fig.add_subplot(2, 4, 6))\n",
    "                ax[5].set_title(\"Output\")  # set title\n",
    "                ax[5].imshow(output,cmap='gray',vmin=0,vmax=1)\n",
    "                \n",
    "                ax[6].set_title(\"Rounded Output\")  # set title\n",
    "                ax[6].imshow(output_rounded,cmap='gray',vmin=0,vmax=1)\n",
    "                \n",
    "                #ax.append(fig.add_subplot(2, 4, 7))\n",
    "                ax[7].set_title(\"GT Output\")  # set title\n",
    "                ax[7].imshow(gt_output,cmap='gray',vmin=0,vmax=1)\n",
    "                \n",
    "                fig.tight_layout()\n",
    "\n",
    "                plt.show()\n",
    "                \n",
    "                print(\"Class Evaluation: \", out_class[0])\n",
    "                print(\"Max Value: \",output.max(),\" Min Value: \",output.min())\n",
    "            \n",
    "        writer.add_scalar('Loss', loss, epoch)\n",
    "\n",
    "        if epoch % 5 == 4:        \n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': net.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                }, save_path+\"epoch_\"+str(epoch+1)+\".pt\")\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d171ccb-b0e5-4dcc-9400-d8da4ba8e7d3",
   "metadata": {
    "id": "9d171ccb-b0e5-4dcc-9400-d8da4ba8e7d3",
    "outputId": "47ed91a7-6a3c-474d-e1b1-db1e2c43c4d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "SimpleNet                                --                        --\n",
       "├─Sequential: 1-1                        [1, 1, 572, 572]          --\n",
       "│    └─Conv2D: 2-1                       [1, 1, 572, 572]          --\n",
       "│    │    └─Conv2d: 3-1                  [1, 1, 572, 572]          6\n",
       "│    └─BatchNorm: 2-2                    [1, 1, 572, 572]          --\n",
       "│    │    └─BatchNorm2d: 3-2             [1, 1, 572, 572]          2\n",
       "│    └─Sigmoid: 2-3                      [1, 1, 572, 572]          --\n",
       "├─Sequential: 1-2                        [1, 1]                    --\n",
       "│    └─Conv2d: 2-4                       [1, 1, 286, 286]          2\n",
       "│    └─Conv2d: 2-5                       [1, 1, 143, 143]          2\n",
       "│    └─Conv2d: 2-6                       [1, 1, 72, 72]            2\n",
       "│    └─Flatten: 2-7                      [1, 5184]                 --\n",
       "│    └─Linear: 2-8                       [1, 1024]                 5,309,440\n",
       "│    └─LeakyReLU: 2-9                    [1, 1024]                 --\n",
       "│    └─Linear: 2-10                      [1, 1]                    1,025\n",
       "│    └─Sigmoid: 2-11                     [1, 1]                    --\n",
       "==========================================================================================\n",
       "Total params: 5,310,479\n",
       "Trainable params: 5,310,479\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 7.49\n",
       "==========================================================================================\n",
       "Input size (MB): 6.54\n",
       "Forward/backward pass size (MB): 6.10\n",
       "Params size (MB): 21.24\n",
       "Estimated Total Size (MB): 33.89\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleNet(5,[1],activation=\"sigmoid\").float().to(device)\n",
    "\n",
    "summary(model, (1,5,572,572))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f41ba74b-ede9-478e-9671-e4cc02c9c93b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on network  [1]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3215/3615124358.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensorboard_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, checkpoint=\"work_dirs/simplenet_1/epoch_25.pt\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_3215/4226381271.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, trainloader, criterion, optimizer, save_path, tensorboard_path, checkpoint)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;31m# get the inputs; data is a list of [inputs, labels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mim_seg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"im_seg\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "OPTIMIZER = \"Adam\"\n",
    "ACTIVATION = \"sigmoid\"\n",
    "LOSS = \"BCELoss\"\n",
    "\n",
    "for layers in [[1],[3],[5]]:\n",
    "    print(\"Starting training on network \",layers)\n",
    "    \n",
    "    net = SimpleNet(N_CHANNELS,layers,activation=ACTIVATION)\n",
    "    net = net.to(device).float()\n",
    "    \n",
    "    if LOSS == \"BCELoss\":\n",
    "        criterion = nn.BCELoss()\n",
    "        \n",
    "    criterion_class = nn.NLLLoss()\n",
    "        \n",
    "        \n",
    "    if OPTIMIZER == \"SGD\":\n",
    "        optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    elif OPTIMIZER == \"Adam\":\n",
    "        optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "    \n",
    "    checkpoint_path = \"work_dirs/simplenet\"\n",
    "    for layer in layers:\n",
    "        checkpoint_path += \"_\"+str(layer)\n",
    "    checkpoint_path += \"/\" + OPTIMIZER + \"_\" + ACTIVATION + \"_\" + LOSS + \"/\"\n",
    "    tensorboard_path = checkpoint_path+\"tb/\"\n",
    "    os.makedirs(tensorboard_path,exist_ok=True)\n",
    "    \n",
    "    train(net,trainloader,(criterion,criterion_class),optimizer, checkpoint_path, tensorboard_path)#, checkpoint=\"work_dirs/simplenet_1/epoch_25.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60d6c84-282f-4049-8d4e-2c30425b19ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "event_acc = EventAccumulator('work_dirs/simplenet_1_1_1/sigmoid_BCELoss/tb')\n",
    "event_acc.Reload()\n",
    "# Show all tags in the log file\n",
    "print(event_acc.Tags())\n",
    "\n",
    "# E. g. get wall clock, number of steps and value for a scalar 'Accuracy'\n",
    "w_times, step_nums, vals = zip(*event_acc.Scalars('Loss'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa04982b-5f79-4198-9209-67c014c52014",
   "metadata": {},
   "source": [
    "# Network Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c87a84b-7af1-4c09-8fef-de23d2071730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1):\n",
    "    data = trainset[i]\n",
    "    \n",
    "    im_seg = data['im_seg']\n",
    "    im_res = data['im_res']\n",
    "    \n",
    "    res = im_seg[0:3,:,:].numpy().transpose((1,2,0))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.imshow(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803644eb-b8fd-4f44-9954-658cea496322",
   "metadata": {
    "id": "803644eb-b8fd-4f44-9954-658cea496322"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e57c266-e2bb-42cc-8dd0-a12cba789a7d",
   "metadata": {
    "id": "6e57c266-e2bb-42cc-8dd0-a12cba789a7d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33d1b8a1-a9f3-44b4-8834-bb5cabb22d55",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bb6ba8-4567-4899-9a91-640cbd8f6918",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ensemble_network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
