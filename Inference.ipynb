{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "889e5cdc-a4f0-4699-b8f7-7707cca995d9",
   "metadata": {},
   "source": [
    "# Base Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a10453-3bac-4b6c-8021-b849a1ef36f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average / weighted_average / bitwise_or\n",
    "ENSEMBLE_METHOD = \"average\"\n",
    "VIABLE_COUNTABILITY = 0\n",
    "AVERAGE_ACCEPTABILITY = 0\n",
    "# Minimum value of credibility per mask\n",
    "CREDIBILITY_THRESHOLD = 0.6\n",
    "# Minimum IoU in order to group instances together\n",
    "DEVIATION_THRESHOLD = 0.5\n",
    "# Minimum IoU in order to compare instances while evaluating \n",
    "DEVIATION_THRESHOLD_EVAL = 0.5\n",
    "#For Weighted Average\n",
    "AVERAGE_ACCEPTABILITY_2 = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5278963b-b35e-4da0-a2d1-34dab1972f80",
   "metadata": {
    "id": "5278963b-b35e-4da0-a2d1-34dab1972f80"
   },
   "source": [
    "# Segmentation Model Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7391a2e3-cc0d-483a-9c93-ebe94d64b483",
   "metadata": {
    "id": "7391a2e3-cc0d-483a-9c93-ebe94d64b483"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_dict = []\n",
    "model_dict.append(('hybrid_task_cascade_mask_rcnn_X-101-64x4d-FPN',('configs/htc/htc_x101_64x4d_fpn_dconv_c3-c5_mstrain_400_1400_16x1_20e_coco.py',\n",
    "                                                                'checkpoints/htc_x101_64x4d_fpn_dconv_c3-c5_mstrain_400_1400_16x1_20e_coco_20200312-946fd751.pth',\n",
    "                                                                'https://download.openmmlab.com/mmdetection/v2.0/htc/htc_x101_64x4d_fpn_dconv_c3-c5_mstrain_400_1400_16x1_20e_coco/htc_x101_64x4d_fpn_dconv_c3-c5_mstrain_400_1400_16x1_20e_coco_20200312-946fd751.pth')))\n",
    "model_dict.append(('detectors_htc_r101_20e_coco',('configs/detectors/detectors_htc_r101_20e_coco.py',\n",
    "                                                  'checkpoints/detectors_htc_r101_20e_coco_20210419_203638-348d533b.pth',\n",
    "                                                  'https://download.openmmlab.com/mmdetection/v2.0/detectors/detectors_htc_r101_20e_coco/detectors_htc_r101_20e_coco_20210419_203638-348d533b.pth')))\n",
    "model_dict.append(('cascade_mask_rcnn_X-101-64x4d-FPN',('configs/cascade_rcnn/cascade_mask_rcnn_x101_64x4d_fpn_mstrain_3x_coco.py',\n",
    "                                                        'checkpoints/cascade_mask_rcnn_x101_64x4d_fpn_mstrain_3x_coco_20210719_210311-d3e64ba0.pth',\n",
    "                                                        'https://download.openmmlab.com/mmdetection/v2.0/cascade_rcnn/cascade_mask_rcnn_x101_64x4d_fpn_mstrain_3x_coco/cascade_mask_rcnn_x101_64x4d_fpn_mstrain_3x_coco_20210719_210311-d3e64ba0.pth')))\n",
    "model_dict.append(('cascade_mask_rcnn_x101_32x4d_fpn_dconv_c3-c5_1x_coco',('configs/dcn/cascade_mask_rcnn_x101_32x4d_fpn_dconv_c3-c5_1x_coco.py',\n",
    "                                                                           'checkpoints/cascade_mask_rcnn_x101_32x4d_fpn_dconv_c3-c5_1x_coco-e75f90c8.pth',\n",
    "                                                                           'https://download.openmmlab.com/mmdetection/v2.0/dcn/cascade_mask_rcnn_x101_32x4d_fpn_dconv_c3-c5_1x_coco/cascade_mask_rcnn_x101_32x4d_fpn_dconv_c3-c5_1x_coco-e75f90c8.pth')))\n",
    "model_dict.append(('gcnet_X-101-FPN_DCN_Cascade_Mask_GC(c3-c5,r4)',('configs/gcnet/cascade_mask_rcnn_x101_32x4d_fpn_syncbn-backbone_dconv_c3-c5_r4_gcb_c3-c5_1x_coco.py',\n",
    "                                                                    'checkpoints/cascade_mask_rcnn_x101_32x4d_fpn_syncbn-backbone_dconv_c3-c5_r4_gcb_c3-c5_1x_coco_20210615_161851-720338ec.pth',\n",
    "                                                                    'https://download.openmmlab.com/mmdetection/v2.0/gcnet/cascade_mask_rcnn_x101_32x4d_fpn_syncbn-backbone_dconv_c3-c5_r4_gcb_c3-c5_1x_coco/cascade_mask_rcnn_x101_32x4d_fpn_syncbn-backbone_dconv_c3-c5_r4_gcb_c3-c5_1x_coco_20210615_161851-720338ec.pth')))\n",
    "\n",
    "key_list = [model[0] for model in model_dict]\n",
    "\n",
    "#test_config = 'configs/common/mstrain-poly_3x_coco_instance.py'\n",
    "test_config = 'configs/_base_/datasets/cityscapes_instance.py'\n",
    "dataset_name = os.path.splitext(test_config)[0].split('/')[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Em6zu5R2uuJP",
   "metadata": {
    "id": "Em6zu5R2uuJP"
   },
   "source": [
    "# Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "Lo5mI3mnutsz",
   "metadata": {
    "id": "Lo5mI3mnutsz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def IoU(boxA, boxB):\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    return iou\n",
    "\n",
    "def IoU_Mask(maskA, maskB):\n",
    "    intersection = np.logical_and(maskA, maskB).astype(np.uint8)\n",
    "    union = np.logical_or(maskA, maskB).astype(np.uint8)\n",
    "    iou = np.sum(intersection)/np.sum(union)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e10b2a-7c6e-467a-9deb-ae38c3a93288",
   "metadata": {},
   "source": [
    "# Ensemble Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb33617e-7633-4fd6-8a14-83e2c045c4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "N_CHANNELS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "956de902-2383-4440-8eb5-09c8ece32bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "import torch\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "    \n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "    \n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "901c5aff-195e-4315-85ee-55888fcd41a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (inc): DoubleConv(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (down1): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down2): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down3): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down4): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up1): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up2): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up3): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up4): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (outc): OutConv(\n",
       "    (conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = UNet(N_CHANNELS,1).float().to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "checkpoint = torch.load(\"work_dirs/u_net_ensemble_network_no_img_0.001_lr/epoch_50.pt\")\n",
    "net.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8130e81d-f008-48ce-a3c1-5f2fb1aaf5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusoi/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "UNet                                          --                        --\n",
       "├─DoubleConv: 1-1                             [4, 64, 572, 572]         --\n",
       "│    └─Sequential: 2-1                        [4, 64, 572, 572]         --\n",
       "│    │    └─Conv2d: 3-1                       [4, 64, 572, 572]         2,944\n",
       "│    │    └─BatchNorm2d: 3-2                  [4, 64, 572, 572]         128\n",
       "│    │    └─ReLU: 3-3                         [4, 64, 572, 572]         --\n",
       "│    │    └─Conv2d: 3-4                       [4, 64, 572, 572]         36,928\n",
       "│    │    └─BatchNorm2d: 3-5                  [4, 64, 572, 572]         128\n",
       "│    │    └─ReLU: 3-6                         [4, 64, 572, 572]         --\n",
       "├─Down: 1-2                                   [4, 128, 286, 286]        --\n",
       "│    └─Sequential: 2-2                        [4, 128, 286, 286]        --\n",
       "│    │    └─MaxPool2d: 3-7                    [4, 64, 286, 286]         --\n",
       "│    │    └─DoubleConv: 3-8                   [4, 128, 286, 286]        221,952\n",
       "├─Down: 1-3                                   [4, 256, 143, 143]        --\n",
       "│    └─Sequential: 2-3                        [4, 256, 143, 143]        --\n",
       "│    │    └─MaxPool2d: 3-9                    [4, 128, 143, 143]        --\n",
       "│    │    └─DoubleConv: 3-10                  [4, 256, 143, 143]        886,272\n",
       "├─Down: 1-4                                   [4, 512, 71, 71]          --\n",
       "│    └─Sequential: 2-4                        [4, 512, 71, 71]          --\n",
       "│    │    └─MaxPool2d: 3-11                   [4, 256, 71, 71]          --\n",
       "│    │    └─DoubleConv: 3-12                  [4, 512, 71, 71]          3,542,016\n",
       "├─Down: 1-5                                   [4, 512, 35, 35]          --\n",
       "│    └─Sequential: 2-5                        [4, 512, 35, 35]          --\n",
       "│    │    └─MaxPool2d: 3-13                   [4, 512, 35, 35]          --\n",
       "│    │    └─DoubleConv: 3-14                  [4, 512, 35, 35]          4,721,664\n",
       "├─Up: 1-6                                     [4, 256, 71, 71]          --\n",
       "│    └─Upsample: 2-6                          [4, 512, 70, 70]          --\n",
       "│    └─DoubleConv: 2-7                        [4, 256, 71, 71]          --\n",
       "│    │    └─Sequential: 3-15                  [4, 256, 71, 71]          5,900,544\n",
       "├─Up: 1-7                                     [4, 128, 143, 143]        --\n",
       "│    └─Upsample: 2-8                          [4, 256, 142, 142]        --\n",
       "│    └─DoubleConv: 2-9                        [4, 128, 143, 143]        --\n",
       "│    │    └─Sequential: 3-16                  [4, 128, 143, 143]        1,475,712\n",
       "├─Up: 1-8                                     [4, 64, 286, 286]         --\n",
       "│    └─Upsample: 2-10                         [4, 128, 286, 286]        --\n",
       "│    └─DoubleConv: 2-11                       [4, 64, 286, 286]         --\n",
       "│    │    └─Sequential: 3-17                  [4, 64, 286, 286]         369,216\n",
       "├─Up: 1-9                                     [4, 64, 572, 572]         --\n",
       "│    └─Upsample: 2-12                         [4, 64, 572, 572]         --\n",
       "│    └─DoubleConv: 2-13                       [4, 64, 572, 572]         --\n",
       "│    │    └─Sequential: 3-18                  [4, 64, 572, 572]         110,976\n",
       "├─OutConv: 1-10                               [4, 1, 572, 572]          --\n",
       "│    └─Conv2d: 2-14                           [4, 1, 572, 572]          65\n",
       "===============================================================================================\n",
       "Total params: 17,268,545\n",
       "Trainable params: 17,268,545\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 796.81\n",
       "===============================================================================================\n",
       "Input size (MB): 26.17\n",
       "Forward/backward pass size (MB): 9547.36\n",
       "Params size (MB): 69.07\n",
       "Estimated Total Size (MB): 9642.61\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(net, (4,5,572,572))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "322abf31-c177-44e8-b475-c26571e5312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "class Resize(object):\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self,sample):\n",
    "        \n",
    "        return resize(sample,(*self.size,N_CHANNELS))\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "\n",
    "        # torch image: C x H x W\n",
    "        sample = sample.transpose((2, 0, 1))\n",
    "        return torch.from_numpy(sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8gLkLqvnvUoM",
   "metadata": {
    "id": "8gLkLqvnvUoM"
   },
   "source": [
    "# Ensemble Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36d5e578-b02b-4660-ad75-8a0a5349bb19",
   "metadata": {
    "id": "a309dfc8-8e8f-4399-8e02-080a64a9b44d"
   },
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "from mmdet.datasets import build_dataset, build_dataloader\n",
    "from mmcv.parallel import MMDataParallel\n",
    "from mmdet.apis import single_gpu_test\n",
    "from mmdet.models import build_detector\n",
    "from mmcv.runner import load_checkpoint\n",
    "from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n",
    "from typing import List, Tuple, Union, Dict\n",
    "from torch import nn\n",
    "from os import path\n",
    "from urllib import request\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import mmcv\n",
    "import os.path as osp\n",
    "import pycocotools.mask as mask_util\n",
    "\n",
    "COCO_CLASSES = ('person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "                'train', 'truck', 'boat', 'traffic light', 'fire hydrant',\n",
    "                'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog',\n",
    "                'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe',\n",
    "                'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "                'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat',\n",
    "                'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "                'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "                'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot',\n",
    "                'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "                'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop',\n",
    "                'mouse', 'remote', 'keyboard', 'cell phone', 'microwave',\n",
    "                'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock',\n",
    "                'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush')\n",
    "\n",
    "CITYSCAPES_CLASSES = ('person', 'rider', 'car', 'truck', 'bus', 'train', 'motorcycle',\n",
    "                      'bicycle')\n",
    "\n",
    "WORK_DIR = \"work_dirs/ensemble_results/\"\n",
    "\n",
    "def get_dataset():\n",
    "    test_cfg = Config.fromfile(test_config)\n",
    "    # in case the test dataset is concatenated\n",
    "    samples_per_gpu = 1\n",
    "    if isinstance(test_cfg.data.test, dict):\n",
    "        test_cfg.data.test.test_mode = True\n",
    "        samples_per_gpu = test_cfg.data.test.pop('samples_per_gpu', 1)\n",
    "        if samples_per_gpu > 1:\n",
    "            # Replace 'ImageToTensor' to 'DefaultFormatBundle'\n",
    "            test_cfg.data.test.pipeline = replace_ImageToTensor(\n",
    "                test_cfg.data.test.pipeline)\n",
    "    elif isinstance(test_cfg.data.test, list):\n",
    "        for ds_cfg in test_cfg.data.test:\n",
    "            ds_cfg.test_mode = True\n",
    "        samples_per_gpu = max(\n",
    "            [ds_cfg.pop('samples_per_gpu', 1) for ds_cfg in test_cfg.data.test])\n",
    "        if samples_per_gpu > 1:\n",
    "            for ds_cfg in test_cfg.data.test:\n",
    "                ds_cfg.pipeline = replace_ImageToTensor(ds_cfg.pipeline)\n",
    "\n",
    "    # init distributed env first, since logger depends on the dist info.\n",
    "    distributed = False\n",
    "\n",
    "    #rank, _ = get_dist_info()\n",
    "    # allows not to create\n",
    "    #mmcv.mkdir_or_exist(osp.abspath(args.work_dir))\n",
    "    #timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())\n",
    "    #json_file = osp.join(args.work_dir, f'eval_{timestamp}.json')\n",
    "\n",
    "    # build the dataloader\n",
    "    dataset = build_dataset(test_cfg.data.test)\n",
    "    data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        samples_per_gpu=samples_per_gpu,\n",
    "        workers_per_gpu=test_cfg.data.workers_per_gpu,\n",
    "        dist=distributed,\n",
    "        shuffle=False)\n",
    "    \n",
    "    return dataset, data_loader\n",
    "\n",
    "def inference_on_dataset(model_info):\n",
    "    config, checkpoint = model_info\n",
    "    \n",
    "    cfg = Config.fromfile(config)\n",
    "\n",
    "    if cfg.get('custom_imports', None):\n",
    "        from mmcv.utils import import_modules_from_strings\n",
    "        import_modules_from_strings(**cfg['custom_imports'])\n",
    "    # set cudnn_benchmark\n",
    "    if cfg.get('cudnn_benchmark', False):\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    cfg.model.pretrained = None\n",
    "    if cfg.model.get('neck'):\n",
    "        if isinstance(cfg.model.neck, list):\n",
    "            for neck_cfg in cfg.model.neck:\n",
    "                if neck_cfg.get('rfp_backbone'):\n",
    "                    if neck_cfg.rfp_backbone.get('pretrained'):\n",
    "                        neck_cfg.rfp_backbone.pretrained = None\n",
    "        elif cfg.model.neck.get('rfp_backbone'):\n",
    "            if cfg.model.neck.rfp_backbone.get('pretrained'):\n",
    "                cfg.model.neck.rfp_backbone.pretrained = None\n",
    "                \n",
    "    test_cfg = Config.fromfile(test_config)\n",
    "    # in case the test dataset is concatenated\n",
    "    samples_per_gpu = 1\n",
    "    if isinstance(cfg.data.test, dict):\n",
    "        test_cfg.data.test.test_mode = True\n",
    "        samples_per_gpu = test_cfg.data.test.pop('samples_per_gpu', 1)\n",
    "        if samples_per_gpu > 1:\n",
    "            # Replace 'ImageToTensor' to 'DefaultFormatBundle'\n",
    "            test_cfg.data.test.pipeline = replace_ImageToTensor(\n",
    "                test_cfg.data.test.pipeline)\n",
    "    elif isinstance(test_cfg.data.test, list):\n",
    "        for ds_cfg in test_cfg.data.test:\n",
    "            ds_cfg.test_mode = True\n",
    "        samples_per_gpu = max(\n",
    "            [ds_cfg.pop('samples_per_gpu', 1) for ds_cfg in test_cfg.data.test])\n",
    "        if samples_per_gpu > 1:\n",
    "            for ds_cfg in test_cfg.data.test:\n",
    "                ds_cfg.pipeline = replace_ImageToTensor(ds_cfg.pipeline)\n",
    "\n",
    "    # init distributed env first, since logger depends on the dist info.\n",
    "    distributed = False\n",
    "\n",
    "    #rank, _ = get_dist_info()\n",
    "    # allows not to create\n",
    "    #mmcv.mkdir_or_exist(osp.abspath(args.work_dir))\n",
    "    #timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())\n",
    "    #json_file = osp.join(args.work_dir, f'eval_{timestamp}.json')\n",
    "\n",
    "    # build the dataloader\n",
    "    dataset = build_dataset(test_cfg.data.test)\n",
    "    data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        samples_per_gpu=samples_per_gpu,\n",
    "        workers_per_gpu=test_cfg.data.workers_per_gpu,\n",
    "        dist=distributed,\n",
    "        shuffle=False)\n",
    "\n",
    "    # build the model and load checkpoint\n",
    "    cfg.model.train_cfg = None\n",
    "    model = build_detector(cfg.model, test_cfg=cfg.get('test_cfg'))\n",
    "    fp16_cfg = cfg.get('fp16', None)\n",
    "    if fp16_cfg is not None:\n",
    "        wrap_fp16_model(model)\n",
    "    checkpoint = load_checkpoint(model, checkpoint, map_location='cpu')\n",
    "    #if args.fuse_conv_bn:\n",
    "        #model = fuse_conv_bn(model)\n",
    "    # old versions did not save class info in checkpoints, this walkaround is\n",
    "    # for backward compatibility\n",
    "    if 'CLASSES' in checkpoint.get('meta', {}):\n",
    "        model.CLASSES = checkpoint['meta']['CLASSES']\n",
    "    else:\n",
    "        model.CLASSES = dataset.CLASSES\n",
    "\n",
    "    #classes = model.CLASSES.copy()\n",
    "    classes = list(enumerate(model.CLASSES)).copy()\n",
    "    model = MMDataParallel(model, device_ids=[0])\n",
    "    outputs = single_gpu_test(model, data_loader, None, None, None)\n",
    "    \n",
    "    print(len(dataset))\n",
    "    \n",
    "    return outputs, classes, len(dataset)\n",
    "\n",
    "\n",
    "def gather_results_from_model(model_name: str, model_info: Tuple[str,str], score_thr:float, person_only:bool , result_type = 'bbox'):\n",
    "    if not osp.exists(WORK_DIR+model_name+\"_\"+dataset_name+\".pkl\"):\n",
    "        mmcv.mkdir_or_exist(osp.abspath(WORK_DIR))\n",
    "        results, original_classes, dataset_size = inference_on_dataset(model_info)\n",
    "        classes = original_classes\n",
    "        mmcv.dump(results, WORK_DIR+model_name+\"_\"+dataset_name+\".pkl\")\n",
    "    else:\n",
    "        config,checkpoint = model_info\n",
    "        cfg = Config.fromfile(config)\n",
    "        model = build_detector(cfg.model)\n",
    "        checkpoint = load_checkpoint(model, checkpoint, map_location='cpu')\n",
    "        if 'CLASSES' in checkpoint.get('meta', {}):\n",
    "            model.CLASSES = checkpoint['meta']['CLASSES']\n",
    "        else:\n",
    "            model.CLASSES = dataset.CLASSES\n",
    "        original_classes = list(enumerate(model.CLASSES)).copy()\n",
    "        classes = original_classes\n",
    "        results = mmcv.load(WORK_DIR+model_name+\"_\"+dataset_name+\".pkl\")\n",
    "        dataset_size = len(results)\n",
    "    if person_only:\n",
    "        if len(classes) == len(COCO_CLASSES):\n",
    "            classes = [(0,'person')]\n",
    "        elif len(classes) == len(CITYSCAPES_CLASSES):\n",
    "            classes = [(0,'person'),(1,'rider')]\n",
    "    \n",
    "        \n",
    "    return results,classes,dataset_size\n",
    "\n",
    "def gather_results(model_dict: Dict[str,Tuple[str,str,str]], score_thr: float, person_only: bool, result_type='bbox'):\n",
    "    #model_dict = model_dict.items()\n",
    "    ensemble_results = {}\n",
    "    dataset_compatible = -1\n",
    "    label_type = []\n",
    "    for i, (name, (config,checkpoint,download_link)) in enumerate(model_dict):\n",
    "        if not path.exists(checkpoint):\n",
    "            print(\"Downloading\",name)\n",
    "            request.urlretrieve(download_link,checkpoint)\n",
    "            print(\"Finished downloading\",name)\n",
    "        print(\"Loading inference results from model:\",name)\n",
    "        ensemble_results[i],classes,dataset_size = gather_results_from_model(name, (config,checkpoint), score_thr, person_only, result_type)\n",
    "        label_type.append(len(classes))\n",
    "        if dataset_compatible < 0 or dataset_compatible == dataset_size:\n",
    "            dataset_compatible = dataset_size\n",
    "        else:\n",
    "            raise(Exception(\"Dataset sizes are not compatible\"))\n",
    "    return ensemble_results,classes,dataset_compatible\n",
    "\n",
    "def group_instances(dataset,model_dict,ensemble_results, labels: List[str], dataset_size, score_thr, threshold, ensemble_method):\n",
    "    #ensemble_results[model][image][bbox or segm][label][instance]\n",
    "    final_results = []\n",
    "    n_models = len(ensemble_results)\n",
    "    #Iterate over all the images\n",
    "    for img in tqdm(range(0,len(dataset))):\n",
    "        bbox_group = []\n",
    "        segm_group = []\n",
    "        \n",
    "        if ensemble_method == \"network\":\n",
    "            filename = dataset[img]['img_metas'][0].data['filename']\n",
    "            ori_img_size = dataset[img]['img_metas'][0].data['ori_shape']\n",
    "            transform = transforms.Compose([Resize((572,572)),ToTensor()])\n",
    "            image = Image.open(filename)\n",
    "            img_array = np.asarray(image)\n",
    "\n",
    "        #Iterate over all the labels\n",
    "        for (label_nr,label) in labels:\n",
    "            bbox_results = []\n",
    "            segm_results = []\n",
    "            #Create a matrix of already used instances\n",
    "            used_instances = []\n",
    "            for cur_model in range(0,len(ensemble_results)):\n",
    "                used_instances.insert(cur_model,[False]*len(ensemble_results[cur_model][img][0][label_nr]))\n",
    "                \n",
    "            #Iterate over all the models for a certain label and a certain image\n",
    "            for cur_model in range(0,len(ensemble_results)):\n",
    "                #Iterate over the current model's results on a certain label on a certain image\n",
    "                for cur_instance in range(0,len(ensemble_results[cur_model][img][0][label_nr])):\n",
    "                    if not used_instances[cur_model][cur_instance] and ensemble_results[cur_model][img][0][label_nr][cur_instance][4] >= CREDIBILITY_THRESHOLD:\n",
    "                    #if not used_instances[cur_model][cur_instance] and ensemble_results[cur_model][img][0][label_nr][cur_instance][4] >= model_dict[cur_model][1][3]:\n",
    "                        used_instances[cur_model][cur_instance] = True\n",
    "                        cur_instance_group = [None for w in range(0,len(ensemble_results))]\n",
    "                        cur_instance_group[cur_model] = (ensemble_results[cur_model][img][0][label_nr][cur_instance],\n",
    "                                                         ensemble_results[cur_model][img][1][label_nr][cur_instance])\n",
    "                        #Iterate over all the other models\n",
    "                        for comp_model in range(cur_model+1,len(ensemble_results)):\n",
    "                            deviations = []\n",
    "                            #Iterate over each of the other model's results\n",
    "                            for comp_instance in range(0,len(ensemble_results[comp_model][img][0][label_nr])):\n",
    "                                if ensemble_results[comp_model][img][0][label_nr][comp_instance][4] >= CREDIBILITY_THRESHOLD:\n",
    "                                    if not used_instances[comp_model][comp_instance]:\n",
    "                                        #cur_iou = IoU(ensemble_results[cur_model][img][0][label_nr][cur_instance],ensemble_results[comp_model][img][0][label_nr][comp_instance])\n",
    "                                        boxA = ensemble_results[cur_model][img][0][label_nr][cur_instance]\n",
    "                                        boxB = ensemble_results[comp_model][img][0][label_nr][comp_instance]\n",
    "                                        xA = int(round(min(boxA[0], boxB[0])))\n",
    "                                        yA = int(round(min(boxA[1], boxB[1])))\n",
    "                                        xB = int(round(max(boxA[2], boxB[2])))\n",
    "                                        yB = int(round(max(boxA[3], boxB[3])))\n",
    "                                        cur_iou = IoU_Mask(mask_util.decode(ensemble_results[cur_model][img][1][label_nr][cur_instance])[yA:yB,xA:xB],\n",
    "                                                           mask_util.decode(ensemble_results[comp_model][img][1][label_nr][comp_instance])[yA:yB,xA:xB])\n",
    "                                        \n",
    "                                    else:\n",
    "                                        cur_iou = 0.0\n",
    "                                    deviations.append(cur_iou)\n",
    "                            #Check if the max iou is within the threshold and add the new instance to the group\n",
    "                            if len(deviations) > 0:\n",
    "                                pos = max(range(len(deviations)), key=deviations.__getitem__)\n",
    "                                if deviations[pos] >= threshold:\n",
    "                                    #Guarantee this instance isn't used again\n",
    "                                    used_instances[comp_model][pos] = True\n",
    "                                    cur_instance_group[comp_model] = (ensemble_results[comp_model][img][0][label_nr][pos],\n",
    "                                                                      ensemble_results[comp_model][img][1][label_nr][pos])\n",
    "                        \n",
    "                        count = 0\n",
    "                        for instance_i in cur_instance_group:\n",
    "                            if instance_i:\n",
    "                                count += 1\n",
    "                                \n",
    "                        # Assuming an instance group is viable if most of the networks identified it\n",
    "                        if (count >= (n_models/2) + VIABLE_COUNTABILITY and (not (ensemble_method == \"bitwise_and\")) and (not (ensemble_method == \"bitwise_or\"))) or \\\n",
    "                           (count == n_models and ensemble_method == \"bitwise_and\") or \\\n",
    "                           (ensemble_method == \"bitwise_or\"):\n",
    "                            bbox = np.array([0.0]*5)\n",
    "                            for model_result in range(0,len(cur_instance_group)):\n",
    "                                if not cur_instance_group[model_result] is None:\n",
    "                                    bbox = np.add(bbox,cur_instance_group[model_result][0])\n",
    "                            bbox = (bbox/count)\n",
    "                            confidence = bbox[4]\n",
    "                            bbox = bbox.astype(int)\n",
    "                            bbox[0:3] = np.around(bbox[0:3])\n",
    "                            bbox_y = (bbox[3]-bbox[1]).astype(int)\n",
    "                            bbox_x = (bbox[2]-bbox[0]).astype(int)\n",
    "                            if ensemble_method == \"network\":\n",
    "                                return_group = []\n",
    "                                for x in range(len(cur_instance_group)):\n",
    "                                    if cur_instance_group[x] is None:\n",
    "                                        return_group.append(np.zeros(ori_img_size,dtype=np.uint8))\n",
    "                                    else:\n",
    "                                        return_group.append(mask_util.decode(cur_instance_group[x][1]))\n",
    "                                pred_stack = np.dstack(return_group)\n",
    "                                #network_input = transform(np.dstack((img_array,pred_stack)))[None,:].float().to(device)\n",
    "                                network_input = transform(pred_stack)[None,:].float().to(device)\n",
    "                                mask = net(network_input)\n",
    "\n",
    "                                mask = mask.cpu().detach()\n",
    "                                mask = mask.numpy().squeeze(axis=0).transpose((1,2,0)).squeeze(axis=2)\n",
    "                                mask = mask > -7\n",
    "\n",
    "                                fig = plt.figure()\n",
    "                                plt.imshow(mask,cmap='gray')\n",
    "                                plt.show()\n",
    "                                img_size = (ori_img_size[0],ori_img_size[1])\n",
    "                                segmentation = mask.astype(\"uint8\")\n",
    "                                \n",
    "                            else:\n",
    "                                mask = np.zeros((bbox_y,bbox_x),dtype=int)\n",
    "                                img_size = (0,0)\n",
    "                                if ensemble_method == \"average\":\n",
    "                                    for model_result in range(0,len(cur_instance_group)):\n",
    "                                        if not cur_instance_group[model_result] is None:\n",
    "                                            decoded_mask = mask_util.decode(cur_instance_group[model_result][1])\n",
    "                                            mask = mask+decoded_mask[bbox[1]:bbox[1]+bbox_y,bbox[0]:bbox[0]+bbox_x].astype(int)\n",
    "                                            img_size = decoded_mask.shape\n",
    "                                    acceptability = max(1,count/2 + AVERAGE_ACCEPTABILITY)\n",
    "                                    mask = mask >= acceptability\n",
    "                                elif ensemble_method == \"weighted_average\":\n",
    "                                    total_confidence = 0.0\n",
    "                                    for model_result in range(0,len(cur_instance_group)):\n",
    "                                        if not cur_instance_group[model_result] is None:\n",
    "                                            decoded_mask = mask_util.decode(cur_instance_group[model_result][1])\n",
    "                                            mask = mask+(decoded_mask[bbox[1]:bbox[1]+bbox_y,bbox[0]:bbox[0]+bbox_x].astype(int) * confidence)\n",
    "                                            total_confidence += confidence\n",
    "                                            img_size = decoded_mask.shape\n",
    "                                    mask = mask >= AVERAGE_ACCEPTABILITY_2 * total_confidence\n",
    "                                elif ensemble_method == \"bitwise_or\":\n",
    "                                    for model_result in range(0,len(cur_instance_group)):\n",
    "                                        if not cur_instance_group[model_result] is None:\n",
    "                                            decoded_mask = mask_util.decode(cur_instance_group[model_result][1])\n",
    "                                            mask = mask+decoded_mask[bbox[1]:bbox[1]+bbox_y,bbox[0]:bbox[0]+bbox_x].astype(int)\n",
    "                                            img_size = decoded_mask.shape\n",
    "                                    mask = mask > 0.0\n",
    "                                elif ensemble_method == \"bitwise_and\":\n",
    "                                    for model_result in range(0,len(cur_instance_group)):\n",
    "                                        decoded_mask = mask_util.decode(cur_instance_group[model_result][1])\n",
    "                                        mask = mask+decoded_mask[bbox[1]:bbox[1]+bbox_y,bbox[0]:bbox[0]+bbox_x].astype(int)\n",
    "                                        img_size = decoded_mask.shape\n",
    "                                    mask = mask == float(n_models)\n",
    "                                    \n",
    "                                segmentation = np.zeros(img_size).astype(bool)\n",
    "                                segmentation[bbox[1]:bbox[1]+bbox_y,bbox[0]:bbox[0]+bbox_x] = mask\n",
    "                            \n",
    "                            \n",
    "                            bbox = bbox.astype(float)\n",
    "                            bbox[4] = confidence\n",
    "                            bbox_results.append(np.array(bbox))\n",
    "                            segm_results.append(mask_util.encode(np.asfortranarray(segmentation)))\n",
    "                            #segm_results.append(np.array(segmentation))\n",
    "            if not bbox_results is None:\n",
    "                np.append(bbox_results,np.array([]))  \n",
    "            bbox_group.append(np.array(bbox_results).reshape(-1,5)) \n",
    "            segm_group.append(segm_results)\n",
    "        final_results.append((bbox_group,segm_group))            \n",
    "                            \n",
    "    return final_results\n",
    "\n",
    "\n",
    "\n",
    "def run_ensemble(dataset, model_dict: Dict[str,Tuple[str,str,str]], score_thr: float, person_only: bool, ensemble_method: str, result_type='segm'):\n",
    "    ensemble_results,classes,dataset_size = gather_results(model_dict,score_thr,person_only,result_type)\n",
    "    results = group_instances(dataset,model_dict,ensemble_results,classes,dataset_size,score_thr,DEVIATION_THRESHOLD,ensemble_method)\n",
    "    #Force garbage collection in order to release memory\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hBw2l47Gve0i",
   "metadata": {
    "id": "hBw2l47Gve0i"
   },
   "source": [
    "# Run Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75e783ac-0bbf-4f81-b5b7-3dec679ec968",
   "metadata": {
    "id": "75e783ac-0bbf-4f81-b5b7-3dec679ec968",
    "outputId": "02550cf4-dc5b-4bc9-c048-0ccab5fa1b4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading inference results from model: hybrid_task_cascade_mask_rcnn_X-101-64x4d-FPN\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "load checkpoint from local path: checkpoints/htc_x101_64x4d_fpn_dconv_c3-c5_mstrain_400_1400_16x1_20e_coco_20200312-946fd751.pth\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>] 1525/1525, 1.2 task/s, elapsed: 1253s, ETA:     0s1525\n",
      "Loading inference results from model: detectors_htc_r101_20e_coco\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "load checkpoint from local path: checkpoints/detectors_htc_r101_20e_coco_20210419_203638-348d533b.pth\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>] 1525/1525, 1.2 task/s, elapsed: 1315s, ETA:     0s1525\n",
      "Loading inference results from model: cascade_mask_rcnn_X-101-64x4d-FPN\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "load checkpoint from local path: checkpoints/cascade_mask_rcnn_x101_64x4d_fpn_mstrain_3x_coco_20210719_210311-d3e64ba0.pth\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 1525/1525, 2.3 task/s, elapsed: 665s, ETA:     0s1525\n",
      "Loading inference results from model: cascade_mask_rcnn_x101_32x4d_fpn_dconv_c3-c5_1x_coco\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "load checkpoint from local path: checkpoints/cascade_mask_rcnn_x101_32x4d_fpn_dconv_c3-c5_1x_coco-e75f90c8.pth\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 1525/1525, 2.3 task/s, elapsed: 664s, ETA:     0s1525\n",
      "Loading inference results from model: gcnet_X-101-FPN_DCN_Cascade_Mask_GC(c3-c5,r4)\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "load checkpoint from local path: checkpoints/cascade_mask_rcnn_x101_32x4d_fpn_syncbn-backbone_dconv_c3-c5_r4_gcb_c3-c5_1x_coco_20210615_161851-720338ec.pth\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 1525/1525, 2.2 task/s, elapsed: 702s, ETA:     0s1525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███                                     | 119/1525 [00:34<06:45,  3.46it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5367/1943031883.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCREDIBILITY_THRESHOLD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mENSEMBLE_METHOD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'segm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#results = get_dataset(model_dict, CREDIBILITY_THRESHOLD,True,ENSEMBLE_METHOD,result_type='segm')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'default'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5367/2561785572.py\u001b[0m in \u001b[0;36mrun_ensemble\u001b[0;34m(dataset, model_dict, score_thr, person_only, ensemble_method, result_type)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_thr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperson_only\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensemble_method\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'segm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0mensemble_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgather_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore_thr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mperson_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mensemble_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore_thr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDEVIATION_THRESHOLD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mensemble_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m     \u001b[0;31m#Force garbage collection in order to release memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5367/2561785572.py\u001b[0m in \u001b[0;36mgroup_instances\u001b[0;34m(dataset, model_dict, ensemble_results, labels, dataset_size, score_thr, threshold, ensemble_method)\u001b[0m\n\u001b[1;32m    358\u001b[0m                             \u001b[0mbbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfidence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m                             \u001b[0mbbox_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m                             \u001b[0msegm_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masfortranarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegmentation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m                             \u001b[0;31m#segm_results.append(np.array(segmentation))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbbox_results\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masfortranarray\u001b[0;34m(a, dtype, like)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asfortranarray_with_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'F'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import warnings\n",
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "dataset,dataloader = get_dataset()\n",
    "results = run_ensemble(dataset,model_dict, CREDIBILITY_THRESHOLD,True,ENSEMBLE_METHOD,result_type='segm')\n",
    "#results = get_dataset(model_dict, CREDIBILITY_THRESHOLD,True,ENSEMBLE_METHOD,result_type='segm')\n",
    "warnings.filterwarnings('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce0e04c4-b838-4ec4-bb0e-089c90c90fd3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'checkpoint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33846/2278499512.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'checkpoint' is not defined"
     ]
    }
   ],
   "source": [
    "checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a3b06a-eceb-4b02-8992-32ef250f9227",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset,dataloader = get_dataset()\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c328a1-84d6-421b-81ee-3de34f26ee57",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8a0d817-2f48-4eee-9c0f-fe99f28adad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.22s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "test_cfg = Config.fromfile(test_config)\n",
    "# in case the test dataset is concatenated\n",
    "samples_per_gpu = 1\n",
    "if isinstance(test_cfg.data.test, dict):\n",
    "    test_cfg.data.test.test_mode = True\n",
    "    samples_per_gpu = test_cfg.data.test.pop('samples_per_gpu', 1)\n",
    "    if samples_per_gpu > 1:\n",
    "        # Replace 'ImageToTensor' to 'DefaultFormatBundle'\n",
    "        test_cfg.data.test.pipeline = replace_ImageToTensor(\n",
    "            test_cfg.data.test.pipeline)\n",
    "elif isinstance(test_cfg.data.test, list):\n",
    "    for ds_cfg in test_cfg.data.test:\n",
    "        ds_cfg.test_mode = True\n",
    "    samples_per_gpu = max(\n",
    "        [ds_cfg.pop('samples_per_gpu', 1) for ds_cfg in test_cfg.data.test])\n",
    "    if samples_per_gpu > 1:\n",
    "        for ds_cfg in test_cfg.data.test:\n",
    "            ds_cfg.pipeline = replace_ImageToTensor(ds_cfg.pipeline)\n",
    "\n",
    "# init distributed env first, since logger depends on the dist info.\n",
    "distributed = False\n",
    "\n",
    "#rank, _ = get_dist_info()\n",
    "# allows not to create\n",
    "#mmcv.mkdir_or_exist(osp.abspath(args.work_dir))\n",
    "#timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())\n",
    "#json_file = osp.join(args.work_dir, f'eval_{timestamp}.json')\n",
    "\n",
    "# build the dataloader\n",
    "dataset = build_dataset(test_cfg.data.test)\n",
    "data_loader = build_dataloader(\n",
    "    dataset,\n",
    "    samples_per_gpu=samples_per_gpu,\n",
    "    workers_per_gpu=test_cfg.data.workers_per_gpu,\n",
    "    dist=distributed,\n",
    "    shuffle=False)\n",
    "\n",
    "#print(metric)\n",
    "#metric_dict = dict(config=args.config, metric=metric)\n",
    "#if args.work_dir is not None and rank == 0:\n",
    "    #mmcv.dump(metric_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9856331f-89f1-4798-806b-97613c8540b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a95494c-5d72-45be-922a-dd695da74d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_kwargs = dict(metric=[\"bbox\",\"segm\"],classwise=True)\n",
    "metric = dataset.evaluate(results, **eval_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cb4f523-9fbc-4d2e-bfd3-2ea8e512ba15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusoi/Desktop/mmdetection/mmdet/datasets/coco.py:698: UserWarning: The key \"bbox\" is deleted for more accurate mask AP of small/medium/large instances since v2.12.0. This does not change the overall mAP calculation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusoi/Desktop/mmdetection/mmdet/datasets/coco.py:589: RuntimeWarning: invalid value encountered in ulong_scalars\n",
      "  iou = np.sum(intersection)/np.sum(union)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP 0.48182 0.62619 0.52591 0.48131 0.46329 0.40000 0.50214 0.46293\n",
      "FP 0.04310 0.15060 0.08331 0.04265 0.04896 0.10000 0.09659 0.04851\n",
      "TN 0.42193 0.15982 0.29424 0.42334 0.43630 0.37500 0.30783 0.43753\n",
      "FN 0.05315 0.06339 0.09654 0.05270 0.05144 0.12500 0.09343 0.05104\n",
      "P 0.64825 0.91874 0.63863 0.90510\n",
      "R 0.63392 0.89843 0.63387 0.89835\n",
      "F1 0.63850 0.90492 0.63307 0.89723\n",
      "CG 8218 0.70559 4 0.02139 82 0.31907 8132 0.72588\n",
      "IG 870 0.07470 1 0.00535 33 0.12840 836 0.07462\n",
      "NG 2559 0.21971 182 0.97326 142 0.55253 2235 0.19950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusoi/anaconda3/envs/pytorch/lib/python3.9/tempfile.py:817: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpyd9vhn54'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n"
     ]
    }
   ],
   "source": [
    "bc_info = dataset.custom_evaluate(results,DEVIATION_THRESHOLD_EVAL)\n",
    "\n",
    "print(\"TP\",\"{:.5f}\".format(np.average([j for sub in list(bc_info['tp'].values()) for j in sub[0]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['tp'].values()) for j in sub[1]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['tp'].values()) for j in sub[2]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['tp'].values()) for j in sub[3]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['tp'].values()) for j in sub[4]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['tp'].values()) for j in sub[5]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['tp'].values()) for j in sub[6]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['tp'].values()) for j in sub[7]])))\n",
    "print(\"FP\",\"{:.5f}\".format(np.average([j for sub in list(bc_info['fp'].values()) for j in sub[0]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['fp'].values()) for j in sub[1]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['fp'].values()) for j in sub[2]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['fp'].values()) for j in sub[3]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['fp'].values()) for j in sub[4]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['fp'].values()) for j in sub[5]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['fp'].values()) for j in sub[6]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['fp'].values()) for j in sub[7]])))\n",
    "print(\"TN\",\"{:.5f}\".format(np.average([j for sub in list(bc_info['tn'].values()) for j in sub[0]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['tn'].values()) for j in sub[1]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['tn'].values()) for j in sub[2]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['tn'].values()) for j in sub[3]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['tn'].values()) for j in sub[4]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['tn'].values()) for j in sub[5]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['tn'].values()) for j in sub[6]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['tn'].values()) for j in sub[7]])))\n",
    "print(\"FN\",\"{:.5f}\".format(np.average([j for sub in list(bc_info['fn'].values()) for j in sub[0]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['fn'].values()) for j in sub[1]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['fn'].values()) for j in sub[2]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['fn'].values()) for j in sub[3]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['fn'].values()) for j in sub[4]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['fn'].values()) for j in sub[5]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['fn'].values()) for j in sub[6]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['fn'].values()) for j in sub[7]])))\n",
    "\n",
    "print(\"P\",\"{:.5f}\".format(np.average([j for sub in list(bc_info['p'].values()) for j in sub[0]])),\n",
    "          \"{:.5f}\".format(np.average([j for sub in list(bc_info['p'].values()) for j in sub[1]])),\n",
    "          \"{:.5f}\".format(np.average([j for sub in list(bc_info['p'].values()) for j in sub[2]])),\n",
    "          \"{:.5f}\".format(np.average([j for sub in list(bc_info['p'].values()) for j in sub[3]])))\n",
    "print(\"R\",\"{:.5f}\".format(np.average([j for sub in list(bc_info['r'].values()) for j in sub[0]])),\n",
    "          \"{:.5f}\".format(np.average([j for sub in list(bc_info['r'].values()) for j in sub[1]])),\n",
    "          \"{:.5f}\".format(np.average([j for sub in list(bc_info['r'].values()) for j in sub[2]])),\n",
    "          \"{:.5f}\".format(np.average([j for sub in list(bc_info['r'].values()) for j in sub[3]])))\n",
    "print(\"F1\",\"{:.5f}\".format(np.average([j for sub in list(bc_info['f1'].values()) for j in sub[0]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['f1'].values()) for j in sub[1]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['f1'].values()) for j in sub[2]])),\n",
    "           \"{:.5f}\".format(np.average([j for sub in list(bc_info['f1'].values()) for j in sub[3]])))\n",
    "\n",
    "cg_list = list(bc_info['cg'].values())\n",
    "ig_list = list(bc_info['ig'].values())\n",
    "ng_list = list(bc_info['ng'].values())\n",
    "cg = np.sum(cg_list,axis=0)\n",
    "ig = np.sum(ig_list,axis=0)\n",
    "ng = np.sum(ng_list,axis=0)\n",
    "\n",
    "total_guesses = sum([cg[0],ig[0],ng[0]])\n",
    "total_guesses_small = sum([cg[1],ig[1],ng[1]])\n",
    "total_guesses_medium = sum([cg[2],ig[2],ng[2]])\n",
    "total_guesses_large = sum([cg[3],ig[3],ng[3]])\n",
    "\n",
    "print(\"CG\",cg[0],\"{:.5f}\".format(cg[0]/total_guesses),\n",
    "           cg[1],\"{:.5f}\".format(cg[1]/total_guesses_small),\n",
    "           cg[2],\"{:.5f}\".format(cg[2]/total_guesses_medium),\n",
    "           cg[3],\"{:.5f}\".format(cg[3]/total_guesses_large))\n",
    "print(\"IG\",ig[0],\"{:.5f}\".format(ig[0]/total_guesses),\n",
    "           ig[1],\"{:.5f}\".format(ig[1]/total_guesses_small),\n",
    "           ig[2],\"{:.5f}\".format(ig[2]/total_guesses_medium),\n",
    "           ig[3],\"{:.5f}\".format(ig[3]/total_guesses_large))\n",
    "print(\"NG\",ng[0],\"{:.5f}\".format(ng[0]/total_guesses),\n",
    "           ng[1],\"{:.5f}\".format(ng[1]/total_guesses_small),\n",
    "           ng[2],\"{:.5f}\".format(ng[2]/total_guesses_medium),\n",
    "           ng[3],\"{:.5f}\".format(ng[3]/total_guesses_large))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46445558-cf60-4f68-be72-652457925084",
   "metadata": {},
   "source": [
    "# Image Viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ad9609eb-3854-4687-8800-150e4292b9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('work_dirs/ensemble_aux/coco_image_names.pickle', 'rb') as handle:\n",
    "    images_names = pickle.load(handle)\n",
    "with open('work_dirs/ensemble_aux/coco_image_names2.pickle', 'rb') as handle:\n",
    "    images_names2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d1e2b41d-d626-4576-9cd1-3124efd20250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ab6ce25-4efb-4d8d-bc83-94633cd4d028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "GT = dataset.gt_return()\n",
    "p = GT\n",
    "print(len(p[139]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18ee1e8d-00aa-45ef-91e9-e52c78d378a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'size': [426, 640], 'counts': b'iP\\\\52W=100O10000O010O10O01N100fNL^E6a:N[E2e:1WE0XOIX;;XE1]OGZ;?eD7N^O\\\\;e1O00000O10001O:F0001N2O1O1OmE_N^8_1oFXOP9b2O2O06H2N2N2N2N2N3PNTF<n9BVF:l9DYF7j9FZF7o9_OUF=S:[OQFa0W:TOPFh0^;K7H8H9G[SX2'}\n"
     ]
    }
   ],
   "source": [
    "print(GT[139][0]['segmentation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8941c935-1e9c-4274-9376-9b9b152b73d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = [\"GT\",\"results/1|2|3|4_e=average_c=0.2_v=-1_d=0.4_a=0.pkl\",\"results/1|2_e=average_c=0.2_v=-1_d=0.4_a=-1.pkl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6c6e67-ebcf-4f98-a8b1-f957df10046b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f2e87d17-ab4d-4449-bc82-7c6dc0d42338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_local loader\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f9d8a28c1454ceca92768148c266788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Select(description='Image', options=('data/coco/val2017/000000000139.jpg', 'data…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import Select,Layout,Output,VBox,HBox\n",
    "from IPython.display import display\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "config, checkpoint,_,_ = model_dict[0][1]\n",
    "model = init_detector(config, checkpoint, device='cuda:0')\n",
    "\n",
    "select = Select(\n",
    "            description=\"Image\",\n",
    "            options=images_names,\n",
    "            value=images_names[0],\n",
    "            rows=15,\n",
    "            disabled=False,\n",
    "        )\n",
    "\n",
    "select2 = Select(\n",
    "            description=\"Ensemble\",\n",
    "            options=result_list,\n",
    "            value=result_list[0],\n",
    "            rows=15,\n",
    "            disabled=False,\n",
    "        )\n",
    "output = Output(\n",
    "            layout=Layout(width='70%')\n",
    "        )\n",
    "\n",
    "\n",
    "display(HBox([VBox([select,select2]),output]))\n",
    "\n",
    "def on_element_clicked(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        if select2.value != \"GT\":\n",
    "            with open(select2.value,\"r\"):\n",
    "                results = mmcv.load(select2.value)\n",
    "                img = images_names2[select.value]\n",
    "                seg_res = []\n",
    "                for i in range(0,len(results[img][1])):\n",
    "                    seg_res2 = []\n",
    "                    for j in range(0,len(results[img][1][i])):\n",
    "                        mask = mask_util.decode(results[img][1][i][j]).astype(bool)\n",
    "                        seg_res2.append(mask)\n",
    "                    seg_res.append(seg_res2)\n",
    "                show_result_pyplot(model, select.value, (results[img][0],seg_res), score_thr=CREDIBILITY_THRESHOLD)\n",
    "        else:\n",
    "            results = GT\n",
    "            img = int(os.path.splitext(select.value)[0].split(\"/\")[-1])\n",
    "            seg_res = []\n",
    "            bbox_res = []\n",
    "            image = Image.open(select.value)\n",
    "            \n",
    "            fig, ax = plt.subplots()\n",
    "            fig.figsize=(10, 8)\n",
    "            fig.dpi=80\n",
    "            ax.imshow(image,aspect='auto')\n",
    "            \n",
    "            for i in range(0,len(results[img])):\n",
    "                bbox_res = results[img][i]['bbox']\n",
    "                bbox = patches.Rectangle((bbox_res[0], bbox_res[1]), bbox_res[2], bbox_res[3], linewidth=1, edgecolor='r', facecolor='none')\n",
    "                ax.add_patch(bbox)\n",
    "                mask = mask_util.decode(results[img][i]['segmentation']).astype(int)\n",
    "                mask = np.ma.masked_values(mask, 0)\n",
    "                \n",
    "                ax.imshow(mask, alpha=0.5, cmap=\"Reds\", interpolation = 'none')\n",
    "                    \n",
    "            print(bbox_res)\n",
    "            \n",
    "            plt.show()\n",
    "            #plt.imshow(img_2, alpha=0.5)\n",
    "            #show_result_pyplot(model, select.value, (bbox_res,seg_res), score_thr=CREDIBILITY_THRESHOLD)\n",
    "\n",
    "select.observe(on_element_clicked)\n",
    "select2.observe(on_element_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f456b6c6-a8a1-4fdb-a3e6-9af1604fed03",
   "metadata": {
    "id": "f456b6c6-a8a1-4fdb-a3e6-9af1604fed03",
    "outputId": "3e913b10-38de-4aee-99ae-1cc198fcb70a"
   },
   "outputs": [],
   "source": [
    "config, checkpoint,_,_ = model_dict[0][1]\n",
    "model = init_detector(config, checkpoint, device='cuda:0')\n",
    "\n",
    "for img in range(0,len(dataset)):\n",
    "    seg_res = []\n",
    "    for i in range(0,len(results[img][1])):\n",
    "        seg_res2 = []\n",
    "        for j in range(0,len(results[img][1][i])):\n",
    "            mask = mask_util.decode(results[img][1][i][j]).astype(bool)\n",
    "            seg_res2.append(mask)\n",
    "        seg_res.append(seg_res2)\n",
    "        \n",
    "    \n",
    "    \n",
    "    print(dataset[img]['img_metas'][0].data['filename'])\n",
    "    show_result_pyplot(model, dataset[img]['img_metas'][0].data['filename'], (results[img][0],seg_res), score_thr=CREDIBILITY_THRESHOLD)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a69d05-8ab6-48fc-aa77-6839204e2709",
   "metadata": {},
   "source": [
    "# Result Recorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "068dbe0c-fecd-48d2-97e2-c7900c3f6baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture cap --no-stderr\n",
    "\n",
    "import gc\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "\n",
    "def ensemble_and_evaluate(model_dict,order):\n",
    "    results = run_ensemble(model_dict, CREDIBILITY_THRESHOLD,True,ENSEMBLE_METHOD,result_type='segm')\n",
    "\n",
    "    title = \"results/\"+('|'.join(str(e) for e in order))+\"_e=\"+str(ENSEMBLE_METHOD)+\"_c=\"+str(CREDIBILITY_THRESHOLD)+\"_v=\"+str(VIABLE_COUNTABILITY)+\"_d=\"+str(DEVIATION_THRESHOLD)\n",
    "    if ENSEMBLE_METHOD == 'average':\n",
    "        title = title + \"_a=\"+str(AVERAGE_ACCEPTABILITY)\n",
    "    elif ENSEMBLE_METHOD == 'weighted_average':\n",
    "        title = title + \"_a2=\"+str(AVERAGE_ACCEPTABILITY_2)\n",
    "    title = title + \".pkl\"\n",
    "    with open(title, 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "\n",
    "    test_cfg = Config.fromfile(test_config)\n",
    "    # in case the test dataset is concatenated\n",
    "    samples_per_gpu = 1\n",
    "    if isinstance(test_cfg.data.test, dict):\n",
    "        test_cfg.data.test.test_mode = True\n",
    "        samples_per_gpu = test_cfg.data.test.pop('samples_per_gpu', 1)\n",
    "        if samples_per_gpu > 1:\n",
    "            # Replace 'ImageToTensor' to 'DefaultFormatBundle'\n",
    "            test_cfg.data.test.pipeline = replace_ImageToTensor(\n",
    "                test_cfg.data.test.pipeline)\n",
    "    elif isinstance(test_cfg.data.test, list):\n",
    "        for ds_cfg in test_cfg.data.test:\n",
    "            ds_cfg.test_mode = True\n",
    "        samples_per_gpu = max(\n",
    "            [ds_cfg.pop('samples_per_gpu', 1) for ds_cfg in test_cfg.data.test])\n",
    "        if samples_per_gpu > 1:\n",
    "            for ds_cfg in test_cfg.data.test:\n",
    "                ds_cfg.pipeline = replace_ImageToTensor(ds_cfg.pipeline)\n",
    "\n",
    "    # init distributed env first, since logger depends on the dist info.\n",
    "    distributed = False\n",
    "\n",
    "    #rank, _ = get_dist_info()\n",
    "    # allows not to create\n",
    "    #mmcv.mkdir_or_exist(osp.abspath(args.work_dir))\n",
    "    #timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())\n",
    "    #json_file = osp.join(args.work_dir, f'eval_{timestamp}.json')\n",
    "\n",
    "    # build the dataloader\n",
    "    dataset = build_dataset(test_cfg.data.test)\n",
    "    data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        samples_per_gpu=samples_per_gpu,\n",
    "        workers_per_gpu=test_cfg.data.workers_per_gpu,\n",
    "        dist=distributed,\n",
    "        shuffle=False)\n",
    "\n",
    "    eval_kwargs = dict(metric=[\"bbox\",\"segm\"],classwise=True)\n",
    "    metric = dataset.evaluate(results, **eval_kwargs)\n",
    "    bc_info = dataset.evaluateBC(results,0.35)\n",
    "    \n",
    "    tps = np.sum(list(bc_info['tp'].values()),axis=0)\n",
    "    fps = np.sum(list(bc_info['fp'].values()),axis=0)\n",
    "    tns = np.sum(list(bc_info['tn'].values()),axis=0)\n",
    "    fns = np.sum(list(bc_info['fn'].values()),axis=0)\n",
    "\n",
    "    #Copiar por aqui\n",
    "\n",
    "    total_1 = sum([tps[0],fps[0],tns[0],fns[0]])\n",
    "    total_1_small = sum([tps[1],fps[1],tns[1],fns[1]])\n",
    "    total_1_medium = sum([tps[2],fps[2],tns[2],fns[2]])\n",
    "    total_1_large = sum([tps[3],fps[3],tns[3],fns[3]])\n",
    "    total_2 = sum([tps[4],fps[4],tns[4],fns[4]])\n",
    "    total_2_small = sum([tps[5],fps[5],tns[5],fns[5]])\n",
    "    total_2_medium = sum([tps[6],fps[6],tns[6],fns[6]])\n",
    "    total_2_large = sum([tps[7],fps[7],tns[7],fns[7]])\n",
    "\n",
    "    print(\"True Positives\",tps[0],\"{:.5f}\".format(tps[0]/total_1),\n",
    "                           tps[1],\"{:.5f}\".format(tps[1]/total_1_small),\n",
    "                           tps[2],\"{:.5f}\".format(tps[2]/total_1_medium),\n",
    "                           tps[3],\"{:.5f}\".format(tps[3]/total_1_large),\n",
    "                           tps[4],\"{:.5f}\".format(tps[4]/total_2),\n",
    "                           tps[5],\"{:.5f}\".format(tps[5]/total_2_small),\n",
    "                           tps[6],\"{:.5f}\".format(tps[6]/total_2_medium),\n",
    "                           tps[7],\"{:.5f}\".format(tps[7]/total_2_large))\n",
    "    print(\"False Positives\",fps[0],\"{:.5f}\".format(fps[0]/total_1),\n",
    "                            fps[1],\"{:.5f}\".format(fps[1]/total_1_small),\n",
    "                            fps[2],\"{:.5f}\".format(fps[2]/total_1_medium),\n",
    "                            fps[3],\"{:.5f}\".format(fps[3]/total_1_large),\n",
    "                            fps[4],\"{:.5f}\".format(fps[4]/total_2),\n",
    "                            fps[5],\"{:.5f}\".format(fps[5]/total_2_small),\n",
    "                            fps[6],\"{:.5f}\".format(fps[6]/total_2_medium),\n",
    "                            fps[7],\"{:.5f}\".format(fps[7]/total_2_large))\n",
    "    print(\"True Negatives\",tns[0],\"{:.5f}\".format(tns[0]/total_1),\n",
    "                           tns[1],\"{:.5f}\".format(tns[1]/total_1_small),\n",
    "                           tns[2],\"{:.5f}\".format(tns[2]/total_1_medium),\n",
    "                           tns[3],\"{:.5f}\".format(tns[3]/total_1_large),\n",
    "                           tns[4],\"{:.5f}\".format(tns[4]/total_2),\n",
    "                           tns[5],\"{:.5f}\".format(tns[5]/total_2_small),\n",
    "                           tns[6],\"{:.5f}\".format(tns[6]/total_2_medium),\n",
    "                           tns[7],\"{:.5f}\".format(tns[7]/total_2_large))\n",
    "    print(\"False Negatives\",fns[0],\"{:.5f}\".format(fns[0]/total_1),\n",
    "                            fns[1],\"{:.5f}\".format(fns[1]/total_1_small),\n",
    "                            fns[2],\"{:.5f}\".format(fns[2]/total_1_medium),\n",
    "                            fns[3],\"{:.5f}\".format(fns[3]/total_1_large),\n",
    "                            fns[4],\"{:.5f}\".format(fns[4]/total_2),\n",
    "                            fns[5],\"{:.5f}\".format(fns[5]/total_2_small),\n",
    "                            fns[6],\"{:.5f}\".format(fns[6]/total_2_medium),\n",
    "                            fns[7],\"{:.5f}\".format(fns[7]/total_2_large))\n",
    "\n",
    "    cg = list(bc_info['correct_guesses'].values())\n",
    "    ig = list(bc_info['incorrect_guesses'].values())\n",
    "    ng = list(bc_info['not_guessed'].values())\n",
    "    correct_guesses = np.sum(cg,axis=0)\n",
    "    incorrect_guesses = np.sum(ig,axis=0)\n",
    "    not_guessed = np.sum(ng,axis=0)\n",
    "\n",
    "    is_crowds = list(bc_info['is_crowd'].values())\n",
    "    crowd_cg = list(zip(cg,is_crowds))\n",
    "    crowd_cg,_ = zip(*[x for x in crowd_cg if x[1] is True])\n",
    "    crowd_ig = list(zip(ig,is_crowds))\n",
    "    crowd_ig,_ = zip(*[x for x in crowd_ig if x[1] is True])\n",
    "    crowd_ng = list(zip(ng,is_crowds))\n",
    "    crowd_ng,_ = zip(*[x for x in crowd_ng if x[1] is True])\n",
    "    crowd_correct_guesses = np.sum(crowd_cg,axis=0)\n",
    "    crowd_incorrect_guesses = np.sum(crowd_ig,axis=0)\n",
    "    crowd_not_guessed = np.sum(crowd_ng,axis=0) \n",
    "        \n",
    "    total_guesses = sum([correct_guesses[0],incorrect_guesses[0],not_guessed[0]])\n",
    "    total_guesses_small = sum([correct_guesses[1],incorrect_guesses[1],not_guessed[1]])\n",
    "    total_guesses_medium = sum([correct_guesses[2],incorrect_guesses[2],not_guessed[2]])\n",
    "    total_guesses_large = sum([correct_guesses[3],incorrect_guesses[3],not_guessed[3]])\n",
    "    total_crowd_guesses = sum([crowd_correct_guesses[0],crowd_incorrect_guesses[0],crowd_not_guessed[0]])\n",
    "    total_crowd_guesses_small = sum([crowd_correct_guesses[1],crowd_incorrect_guesses[1],crowd_not_guessed[1]])\n",
    "    total_crowd_guesses_medium = sum([crowd_correct_guesses[2],crowd_incorrect_guesses[2],crowd_not_guessed[2]])\n",
    "    total_crowd_guesses_large = sum([crowd_correct_guesses[3],crowd_incorrect_guesses[3],crowd_not_guessed[3]])\n",
    "    \n",
    "    print(\"Correct Guesses\",correct_guesses[0],\"{:.5f}\".format(correct_guesses[0]/total_guesses),\n",
    "                            correct_guesses[1],\"{:.5f}\".format(correct_guesses[1]/total_guesses_small),\n",
    "                            correct_guesses[2],\"{:.5f}\".format(correct_guesses[2]/total_guesses_medium),\n",
    "                            correct_guesses[3],\"{:.5f}\".format(correct_guesses[3]/total_guesses_large),\n",
    "                            crowd_correct_guesses[0],\"{:.5f}\".format(crowd_correct_guesses[0]/total_crowd_guesses),\n",
    "                            crowd_correct_guesses[1],\"{:.5f}\".format(crowd_correct_guesses[1]/total_crowd_guesses_small),\n",
    "                            crowd_correct_guesses[2],\"{:.5f}\".format(crowd_correct_guesses[2]/total_crowd_guesses_medium),\n",
    "                            crowd_correct_guesses[3],\"{:.5f}\".format(crowd_correct_guesses[3]/total_crowd_guesses_large))\n",
    "    print(\"Incorrect Guesses\",incorrect_guesses[0],\"{:.5f}\".format(incorrect_guesses[0]/total_guesses),\n",
    "                              incorrect_guesses[1],\"{:.5f}\".format(incorrect_guesses[1]/total_guesses_small),\n",
    "                              incorrect_guesses[2],\"{:.5f}\".format(incorrect_guesses[2]/total_guesses_medium),\n",
    "                              incorrect_guesses[3],\"{:.5f}\".format(incorrect_guesses[3]/total_guesses_large),\n",
    "                              crowd_incorrect_guesses[0],\"{:.5f}\".format(crowd_incorrect_guesses[0]/total_crowd_guesses),\n",
    "                              crowd_incorrect_guesses[1],\"{:.5f}\".format(crowd_incorrect_guesses[1]/total_crowd_guesses_small),\n",
    "                              crowd_incorrect_guesses[2],\"{:.5f}\".format(crowd_incorrect_guesses[2]/total_crowd_guesses_medium),\n",
    "                              crowd_incorrect_guesses[3],\"{:.5f}\".format(crowd_incorrect_guesses[3]/total_crowd_guesses_large))\n",
    "    print(\"Not Guessed\",not_guessed[0],\"{:.5f}\".format(not_guessed[0]/total_guesses),\n",
    "                        not_guessed[1],\"{:.5f}\".format(not_guessed[1]/total_guesses_small),\n",
    "                        not_guessed[2],\"{:.5f}\".format(not_guessed[2]/total_guesses_medium),\n",
    "                        not_guessed[3],\"{:.5f}\".format(not_guessed[3]/total_guesses_large),\n",
    "                        crowd_not_guessed[0],\"{:.5f}\".format(crowd_not_guessed[0]/total_crowd_guesses),\n",
    "                        crowd_not_guessed[1],\"{:.5f}\".format(crowd_not_guessed[1]/total_crowd_guesses_small),\n",
    "                        crowd_not_guessed[2],\"{:.5f}\".format(crowd_not_guessed[2]/total_crowd_guesses_medium),\n",
    "                        crowd_not_guessed[3],\"{:.5f}\".format(crowd_not_guessed[3]/total_crowd_guesses_large))\n",
    "    \n",
    "\n",
    "def ordering_recursion(models, missing_iterations, used_array, order_array):\n",
    "    if missing_iterations == 0:\n",
    "        ordered_model_dict = []\n",
    "        print(\"Model Order: \",end=\"\")\n",
    "        for i in range(0,len(order_array)):\n",
    "            ordered_model_dict.append(models[order_array[i]])\n",
    "            print(ordered_model_dict[i][0],end=\" -> \")\n",
    "        print(\"\")\n",
    "        ensemble_and_evaluate(ordered_model_dict,order_array)\n",
    "    else:\n",
    "        for i in range(0, len(models)):\n",
    "            if not used_array[i]:\n",
    "                cur_used_array = used_array.copy()\n",
    "                cur_used_array[i] = True\n",
    "                cur_order_array = order_array.copy()\n",
    "                cur_order_array.append(i)\n",
    "                ordering_recursion(models,missing_iterations-1,cur_used_array,cur_order_array)\n",
    "\n",
    "def non_ordered_recursion(models, next_model, missing_iterations, used_array, order_array):       \n",
    "    if missing_iterations == 0:\n",
    "        ordered_model_dict = []\n",
    "        print(\"Model Order: \",end=\"\")\n",
    "        for i in range(0,len(order_array)):\n",
    "            ordered_model_dict.append(models[order_array[i]])\n",
    "            print(ordered_model_dict[i][0],end=\" -> \")\n",
    "        print(\"\")\n",
    "        ensemble_and_evaluate(ordered_model_dict,order_array)\n",
    "    else:\n",
    "        for i in range(next_model, len(models)):\n",
    "            if not used_array[i]:\n",
    "                cur_used_array = used_array.copy()\n",
    "                cur_used_array[i] = True\n",
    "                cur_order_array = order_array.copy()\n",
    "                cur_order_array.append(i)\n",
    "                non_ordered_recursion(models,i,missing_iterations-1,cur_used_array,cur_order_array)\n",
    "                \n",
    "def ensemble_permutations(models):\n",
    "    used_array = [False] * len(models)\n",
    "    for i in range(1,len(models)+1):\n",
    "        non_ordered_recursion(models,0, i, used_array, [])\n",
    "        #ordering_recursion(models, i, used_array, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "98e55a70-f445-47c6-b62e-0d566cf20281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Order: mask_rcnn_r50_fpn_1x_cityscapes -> \n",
      "Loading inference results from model: mask_rcnn_r50_fpn_1x_cityscapes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusoi/Desktop/mmdetection/mmdet/core/anchor/builder.py:16: UserWarning: ``build_anchor_generator`` would be deprecated soon, please use ``build_prior_generator`` \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_local loader\n",
      "([array([[386.69058   ,  77.156815  , 498.77228   , 345.02853   ,\n",
      "          0.99998236]], dtype=float32), array([], shape=(0, 5), dtype=float32), array([], shape=(0, 5), dtype=float32), array([], shape=(0, 5), dtype=float32), array([], shape=(0, 5), dtype=float32), array([], shape=(0, 5), dtype=float32), array([], shape=(0, 5), dtype=float32), array([], shape=(0, 5), dtype=float32)], [[{'size': [427, 640], 'counts': b'^`R5=i<a0@9G5N2_KROaLQ1Y3VOdLk0Z3YOcLi0Z3ZOWLT1h3oNoKX1n3nNRKZOUNo1g6kNhJU2W5mMcJX2\\\\5jMVJc2i5`MjIk2U6XMbIn2^6P2N2M2O11N1N3M2O1O1L3M301N3K4K6M3M3M3K5M2N3J6I6N2OM2^Ob0N4O102N10001O3L4M3M2N5K7I4L2N7I;E6J4L7I5K3M2N1O1O1O1O3M1O2N00000001O0mLdKWM]4Y2YL`Mh3W2dLeM]3Q2oLkMT3`1dMXNa2c1fMVN_2e1hMUN[2i1nMmMW2P2f4K5\\\\MlEi1l:O2N2O1N2O1O1N2O0O3L3N2N1O3L4L3M2N3M6I5L4KdQk1'}], [], [], [], [], [], [], []])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████                            | 1326/5000 [00:01<00:05, 692.43it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5348/2742102152.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mperm_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble_permutations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_5348/1045339832.py\u001b[0m in \u001b[0;36mensemble_permutations\u001b[0;34m(models)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mused_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mnon_ordered_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mused_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;31m#ordering_recursion(models, i, used_array, [])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5348/1045339832.py\u001b[0m in \u001b[0;36mnon_ordered_recursion\u001b[0;34m(models, next_model, missing_iterations, used_array, order_array)\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0mcur_order_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morder_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mcur_order_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                 \u001b[0mnon_ordered_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmissing_iterations\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcur_used_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcur_order_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mensemble_permutations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5348/1045339832.py\u001b[0m in \u001b[0;36mnon_ordered_recursion\u001b[0;34m(models, next_model, missing_iterations, used_array, order_array)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mordered_model_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" -> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mensemble_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mordered_model_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morder_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5348/1045339832.py\u001b[0m in \u001b[0;36mensemble_and_evaluate\u001b[0;34m(model_dict, order)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mensemble_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCREDIBILITY_THRESHOLD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mENSEMBLE_METHOD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'segm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"results/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'|'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_e=\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mENSEMBLE_METHOD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_c=\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCREDIBILITY_THRESHOLD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_v=\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVIABLE_COUNTABILITY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_d=\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVIATION_THRESHOLD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5348/3004242320.py\u001b[0m in \u001b[0;36mrun_ensemble\u001b[0;34m(model_dict, score_thr, person_only, ensemble_method, result_type)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0mensemble_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgather_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore_thr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mperson_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensemble_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mensemble_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore_thr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDEVIATION_THRESHOLD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mensemble_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m     \u001b[0;31m#Force garbage collection in order to release memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5348/3004242320.py\u001b[0m in \u001b[0;36mgroup_instances\u001b[0;34m(model_dict, ensemble_results, labels, dataset_size, score_thr, threshold, ensemble_method)\u001b[0m\n\u001b[1;32m    237\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0mmodel_result\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_instance_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcur_instance_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_result\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                                         \u001b[0mdecoded_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_instance_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_result\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m                                         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdecoded_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbbox_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbbox_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                                         \u001b[0mimg_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoded_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/pycocotools/mask.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(rleObjs)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrleObjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrleObjs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0marea\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrleObjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "perm_results = ensemble_permutations(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6958f21d-6d87-4ea7-8f27-9c9cd327a701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Inference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
