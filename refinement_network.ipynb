{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abd8276-9a15-493d-9702-193567232dc8",
   "metadata": {
    "id": "7abd8276-9a15-493d-9702-193567232dc8"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "N_CHANNELS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6e7996-329c-4b1e-9096-66673a04f309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "import torch\n",
    "from network_definitions.u_net import UNet\n",
    "from network_definitions.fcn import FCN32s as FCN\n",
    "from network_definitions.simple_network import SimpleNet\n",
    "from network_definitions.pyramid_network import PyramidNet\n",
    "from torchvision.models.segmentation import fcn_resnet101 as FCN_Res101"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125d6836-3303-4a58-909e-e8ebbf7c36b8",
   "metadata": {
    "id": "125d6836-3303-4a58-909e-e8ebbf7c36b8"
   },
   "source": [
    "# Dataset Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d8e490-235c-4b8b-86e4-5032f56012c5",
   "metadata": {
    "id": "a6d8e490-235c-4b8b-86e4-5032f56012c5",
    "outputId": "5f5e2dec-91aa-46b3-d42b-e40967cada91"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import pickle\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "class PatchesDatasetTrain(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return 20000\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        inp = io.imread(self.root_dir+\"/inp/\"+str(idx)+\".png\")\n",
    "        gt = io.imread(self.root_dir+\"/gt/\"+str(idx)+\".png\",as_gray=True)\n",
    "        \n",
    "        sample = {'name': idx, 'inp': inp, 'gt': gt}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "    \n",
    "class PatchesDatasetTest(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return 4629\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        inp = io.imread(self.root_dir+\"/inp/\"+str(idx+20000)+\".png\")\n",
    "        gt = io.imread(self.root_dir+\"/gt/\"+str(idx+20000)+\".png\",as_gray=True)\n",
    "        \n",
    "        sample = {'name': idx, 'inp': inp, 'gt': gt}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "        \n",
    "    \n",
    "from skimage.transform import resize\n",
    "from torchvision import transforms, utils\n",
    "    \n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        name,inp,gt = sample[\"name\"],sample[\"inp\"],sample[\"gt\"]\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C x H x W\n",
    "        inp = inp.transpose((2, 0, 1))/255\n",
    "        gt = gt[:,:,np.newaxis].transpose((2, 0, 1))/255\n",
    "        return {\"name\": name, \n",
    "                \"inp\": torch.from_numpy(inp),\n",
    "                \"gt\": torch.from_numpy(gt)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8933d255-781d-47e7-a4df-af65c74a37a1",
   "metadata": {
    "id": "8933d255-781d-47e7-a4df-af65c74a37a1",
    "outputId": "b0e15282-db09-460f-e923-ed51732716d4"
   },
   "outputs": [],
   "source": [
    "trainset = PatchesDatasetTrain(\"data/cityscapes_patches\", \n",
    "                               transform=transforms.Compose([ToTensor()]))\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=6)\n",
    "\n",
    "\"\"\"trainset = EnsembleDataset(image_dir='data/coco/test2017',\n",
    "                           results_file='',\n",
    "                           transform=transforms.Compose([Rescale(256),\n",
    "                                                         RandomCrop(224),\n",
    "                                                         ToTensor()]))\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd411d2a-1831-42ce-9a2c-b8e61ef675ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79005d77-36ac-4f74-8b20-74f6c6ac50c5",
   "metadata": {
    "id": "79005d77-36ac-4f74-8b20-74f6c6ac50c5"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b1957d-e096-404f-ba42-6e3f3cf717a5",
   "metadata": {
    "id": "04b1957d-e096-404f-ba42-6e3f3cf717a5"
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import cv2\n",
    "\n",
    "#PATH = \"work_dirs/simplenet_1/\"\n",
    "\n",
    "\n",
    "def train(net, trainloader, criterion, optimizer, save_path, tensorboard_path, checkpoint=None):\n",
    "    \n",
    "    EPOCH = 0\n",
    "    \n",
    "    writer = SummaryWriter(log_dir=tensorboard_path)\n",
    "    \n",
    "    if checkpoint != None:\n",
    "        checkpoint = torch.load(checkpoint)\n",
    "        net.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        EPOCH = checkpoint['epoch']\n",
    "        loss = checkpoint['loss']\n",
    "        net.train()\n",
    "    \n",
    "    for epoch in range(EPOCH,1000):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            im_seg = data[\"inp\"].to(device, dtype=torch.float)\n",
    "            im_res = data[\"gt\"].to(device, dtype=torch.long)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # forward + backward + optimize\n",
    "            output = net(im_seg.float())\n",
    "            \n",
    "            loss = criterion(output.float(), im_res.float())\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if i % 100 == 99:    # print every 100 mini-batches\n",
    "                \"\"\"print('[%d, %5d] segm loss: %.6f  class loss: %.6f  loss: %.6f' %\n",
    "                      (epoch + 1, i + 1, running_loss_segm / 50, running_loss_class / 50, running_loss / 50))\"\"\"\n",
    "                print('[%d, %5d] loss: %.6f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 99))\n",
    "                running_loss = 0.0\n",
    "                \n",
    "                input_ = im_seg.cpu().detach()\n",
    "                output_ = output.cpu().detach()\n",
    "                #output_ = torch.argmax(output_,1)\n",
    "                #print(output_.shape)\n",
    "                gt_output_ = im_res.cpu().detach()\n",
    "                \n",
    "                input_ = input_.numpy()[0].transpose((1,2,0))\n",
    "                output_ = output_.numpy()[0].transpose((1,2,0))\n",
    "                \n",
    "                gt_output_ = gt_output_.numpy()[0].transpose((1,2,0)).squeeze(axis=2)\n",
    "                \n",
    "                print(np.amax(output_))\n",
    "                \n",
    "                fig, ax = plt.subplots(nrows=1, ncols=5, figsize=(15,15))\n",
    "                ax=ax.flat\n",
    "                    \n",
    "                ax[0].set_title(\"Original Image Patch\")  # set title\n",
    "                ax[0].imshow(cv2.cvtColor(input_[:,:,0:3], cv2.COLOR_BGR2RGB))\n",
    "                \n",
    "                #ax.append(fig.add_subplot(2, 4, 7))\n",
    "                ax[1].set_title(\"Boundary Input\")  # set title\n",
    "                ax[1].imshow(input_[:,:,3],cmap='gray')\n",
    "                \n",
    "                ax[2].set_title(\"Boundary Output\")\n",
    "                ax[2].imshow(output_,cmap='gray')\n",
    "                \n",
    "                ax[3].set_title(\"Boundary Output Thresholded\")\n",
    "                ax[3].imshow(np.around(output_),cmap='gray')\n",
    "                \n",
    "                ax[4].set_title(\"Ground Truth\")\n",
    "                ax[4].imshow(gt_output_,cmap='gray')\n",
    "                \n",
    "                fig.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                print(\"Max Value: \",output_.max(),\" Min Value: \",output_.min())\n",
    "            \n",
    "        writer.add_scalar('Loss', loss, epoch)\n",
    "\n",
    "        if epoch % 10 == 9:        \n",
    "            torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': net.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': loss,\n",
    "                    }, save_path+\"epoch_\"+str(epoch+1)+\".pt\")    \n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41ba74b-ede9-478e-9671-e4cc02c9c93b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "OPTIMIZER = \"SGD\"\n",
    "LOSS = \"BCELoss\"\n",
    "\n",
    "print(\"Starting training on network: UNet \")\n",
    "\n",
    "net = UNet(4,1)\n",
    "net = net.to(device).float()\n",
    "\n",
    "if LOSS == \"BCELoss\":\n",
    "    criterion = nn.BCELoss()\n",
    "elif LOSS == \"CrossEntropyLoss\":\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if OPTIMIZER == \"SGD\":\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "elif OPTIMIZER == \"Adam\":\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "checkpoint_path = \"work_dirs/unet_boundary_refinement/\"\n",
    "tensorboard_path = checkpoint_path+\"tb/\"\n",
    "os.makedirs(tensorboard_path,exist_ok=True)\n",
    "\n",
    "train(net,trainloader,criterion,optimizer, checkpoint_path, tensorboard_path)#, checkpoint=\"work_dirs/simplenet_1/epoch_25.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d171ccb-b0e5-4dcc-9400-d8da4ba8e7d3",
   "metadata": {
    "id": "9d171ccb-b0e5-4dcc-9400-d8da4ba8e7d3",
    "outputId": "47ed91a7-6a3c-474d-e1b1-db1e2c43c4d7"
   },
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(4,2).float().to(device)\n",
    "\n",
    "summary(model, (1,4,64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60d6c84-282f-4049-8d4e-2c30425b19ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "event_acc = EventAccumulator('work_dirs/simplenet_1_1_1/sigmoid_BCELoss/tb')\n",
    "event_acc.Reload()\n",
    "# Show all tags in the log file\n",
    "print(event_acc.Tags())\n",
    "\n",
    "# E. g. get wall clock, number of steps and value for a scalar 'Accuracy'\n",
    "w_times, step_nums, vals = zip(*event_acc.Scalars('Loss'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa04982b-5f79-4198-9209-67c014c52014",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351e11dd-f8b9-4d24-8046-895cbb821793",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = PatchesDatasetTest(\"data/cityscapes_patches\", \n",
    "                               transform=transforms.Compose([ToTensor()]))\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803644eb-b8fd-4f44-9954-658cea496322",
   "metadata": {
    "id": "803644eb-b8fd-4f44-9954-658cea496322"
   },
   "outputs": [],
   "source": [
    "def test(net, testloader):\n",
    "    \n",
    "    aoa_inp,ap_inp,ar_inp,f1_inp,aoa_pred,ap_pred,ar_pred,f1_pred = 0,0,0,0,0,0,0,0\n",
    "    \n",
    "    for i, data in enumerate(testloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        im_seg = data[\"inp\"].to(device, dtype=torch.float)\n",
    "        im_res = data[\"gt\"].to(device, dtype=torch.long)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        output = net(im_seg.float())\n",
    "\n",
    "        input_ = im_seg.cpu().detach()\n",
    "        output_ = output.cpu().detach()\n",
    "        #output_ = torch.argmax(output_,1)\n",
    "        #print(output_.shape)\n",
    "        gt_output_ = im_res.cpu().detach()\n",
    "\n",
    "        pos_input_ = input_.numpy()[0].transpose((1,2,0))\n",
    "        pos_output_ = output_.numpy()[0].transpose((1,2,0))\n",
    "\n",
    "        pos_gt_output_ = gt_output_.numpy()[0].transpose((1,2,0)).squeeze(axis=2)\n",
    "\n",
    "        #print(np.amax(output_))\n",
    "\n",
    "        \"\"\"fig, ax = plt.subplots(nrows=1, ncols=5, figsize=(15,15))\n",
    "        ax=ax.flat\n",
    "\n",
    "        ax[0].set_title(\"Original Image Patch\")  # set title\n",
    "        ax[0].imshow(cv2.cvtColor(pos_input_[:,:,0:3], cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        #ax.append(fig.add_subplot(2, 4, 7))\n",
    "        ax[1].set_title(\"Boundary Input\")  # set title\n",
    "        ax[1].imshow(pos_input_[:,:,3],cmap='gray')\n",
    "\n",
    "        ax[2].set_title(\"Boundary Output\")\n",
    "        ax[2].imshow(pos_output_,cmap='gray')\n",
    "\n",
    "        ax[3].set_title(\"Boundary Output Thresholded\")\n",
    "        ax[3].imshow(np.around(pos_output_),cmap='gray')\n",
    "\n",
    "        ax[4].set_title(\"Ground Truth\")\n",
    "        ax[4].imshow(pos_gt_output_,cmap='gray')\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.show()\"\"\"\n",
    "        \n",
    "        output_ = np.around(output_)\n",
    "        \n",
    "        tp_inp = np.count_nonzero(np.logical_and(gt_output_,input_[:,3,:,:,][:,np.newaxis,:,:]))\n",
    "        fp_inp = np.count_nonzero(np.logical_and(np.logical_not(gt_output_),input_[:,3,:,:,][:,np.newaxis,:,:]))\n",
    "        tn_inp = np.count_nonzero(np.logical_and(np.logical_not(gt_output_),np.logical_not(input_[:,3,:,:,][:,np.newaxis,:,:])))\n",
    "        fn_inp = np.count_nonzero(np.logical_and(gt_output_,np.logical_not(input_[:,3,:,:,][:,np.newaxis,:,:])))\n",
    "        oa_inp = (tp_inp+tn_inp)/(tp_inp+fp_inp+tn_inp+fn_inp)\n",
    "        p_inp = tp_inp/(tp_inp+fp_inp)\n",
    "        r_inp = tp_inp/(tp_inp+fn_inp)\n",
    "        \n",
    "        tp_pred = np.count_nonzero(np.logical_and(gt_output_,output_))\n",
    "        fp_pred = np.count_nonzero(np.logical_and(np.logical_not(gt_output_),output_))\n",
    "        tn_pred = np.count_nonzero(np.logical_and(np.logical_not(gt_output_),np.logical_not(output_)))\n",
    "        fn_pred = np.count_nonzero(np.logical_and(gt_output_,np.logical_not(output_)))\n",
    "        oa_pred = (tp_pred+tn_pred)/(tp_pred+fp_pred+tn_pred+fn_pred)\n",
    "        p_pred = tp_pred/(tp_pred+fp_pred)\n",
    "        r_pred = tp_pred/(tp_pred+fn_pred)\n",
    "        \n",
    "        aoa_inp += oa_inp\n",
    "        ap_inp += p_inp\n",
    "        ar_inp += r_inp\n",
    "        f1_inp += (2*p_inp*r_inp)/(p_inp+r_inp)\n",
    "        aoa_pred += oa_pred\n",
    "        ap_pred += p_pred\n",
    "        ar_pred += r_pred\n",
    "        f1_pred += (2*p_pred*r_pred)/(p_pred+r_pred)\n",
    "    \n",
    "    aoa_inp /= len(testloader)\n",
    "    ap_inp /= len(testloader)\n",
    "    ar_inp /= len(testloader)\n",
    "    f1_inp /= len(testloader)\n",
    "    aoa_pred /= len(testloader)\n",
    "    ap_pred /= len(testloader)\n",
    "    ar_pred /= len(testloader)\n",
    "    f1_pred /= len(testloader)\n",
    "        \n",
    "    \n",
    "    print(\"Accuracy Input: \"+str(aoa_inp)+\"  Precision Input: \"+str(ap_inp)+\"  Recall Input: \"+str(ar_inp)+\"  F1 Input: \"+str(f1_inp))\n",
    "    print(\"Accuracy Prediction: \"+str(aoa_pred)+\"  Precision Prediction: \"+str(ap_pred)+\"  Recall Prediction: \"+str(ar_pred)+\"  F1 Prediction: \"+str(f1_pred))\n",
    "\n",
    "    \n",
    "    return oa_pred,ap_pred,ar_pred,f1_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d0a7db-c86a-4e3d-b996-c4294ee2a7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_oa = []\n",
    "results_p = []\n",
    "results_r = []\n",
    "results_f1 = []\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = UNet(4,1)\n",
    "net = net.to(device).float()\n",
    "\n",
    "for i in range(10,1001,10):\n",
    "    checkpoint = \"work_dirs/unet_boundary_refinement/epoch_\"+str(i)+\".pt\"\n",
    "\n",
    "    checkpoint = torch.load(checkpoint)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    net.eval()\n",
    "    \n",
    "    print(\"Epoch \"+str(i))\n",
    "    oa,ap,ar,f1 = test(net,testloader)\n",
    "    results_oa.append(oa)\n",
    "    results_p.append(ap)\n",
    "    results_r.append(ar)\n",
    "    results_f1.append(f1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# line 1 points\n",
    "x0 = list(range(10,1001,10))\n",
    "y0 = results_oa\n",
    "# plotting the line 1 points \n",
    "plt.plot(x0, y0, label = \"Average Overall Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "# line 1 points\n",
    "x1 = list(range(10,1001,10))\n",
    "y1 = results_p\n",
    "# plotting the line 1 points \n",
    "plt.plot(x1, y1, label = \"Average Precision\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# line 2 points\n",
    "x2 = list(range(10,1001,10))\n",
    "y2 = results_r\n",
    "# plotting the line 2 points \n",
    "plt.plot(x2, y2, label = \"Average Recall\")\n",
    "plt.show()\n",
    "\n",
    "# line 1 points\n",
    "x3 = list(range(10,1001,10))\n",
    "y3 = results_f1\n",
    "# plotting the line 1 points \n",
    "plt.plot(x3, y3, label = \"Average F1 Score\")\n",
    "# Display a figure.\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bb6ba8-4567-4899-9a91-640cbd8f6918",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ensemble_network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
